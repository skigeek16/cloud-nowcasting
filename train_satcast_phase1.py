# train_satcast_phase1.py
import torch
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.distributed import DistributedSampler
import numpy as np
import os
import torch.nn.functional as F
from tqdm import tqdm
from collections import OrderedDict
from copy import deepcopy

# Import the new Unet3D model
from unet_cuboid import Unet3D

# --- Configuration ---
SATELLITE_DATA_DIR = './satellite_imagery/' # Dir with raw satellite frames (e.g., TIR1 BT)
FUXI_FORECAST_DIR = './fuxi_forecasts/'    # Dir with forecasts generated by the FuXi model
EPOCHS = 300
BATCH_SIZE = 2
LEARNING_RATE = 5e-5
TIMESTEPS = 1000 # Diffusion timesteps
PAST_FRAMES = 8
FUTURE_FRAMES = 4 # Phase 1 predicts 4 frames (2 hours)
FUXI_CONDITION_FRAMES = 12 # FuXi provides 12 frames of context

# --- Diffusion Helpers ---
def linear_beta_schedule(timesteps):
    beta_start = 0.0001
    beta_end = 0.02
    return torch.linspace(beta_start, beta_end, timesteps)

betas = linear_beta_schedule(TIMESTEPS)
alphas = 1.0 - betas
alphas_cumprod = torch.cumprod(alphas, axis=0)
sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)
sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)

def extract(a, t, x_shape):
    batch_size = t.shape[0]
    out = a.gather(-1, t.cpu())
    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)

def q_sample(x_start, t, noise=None):
    if noise is None:
        noise = torch.randn_like(x_start)
    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)
    sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x_start.shape)
    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise

# --- Dataset ---
class SatcastDataset(Dataset):
    def __init__(self, sat_dir, fuxi_dir, sat_files):
        self.sat_dir = sat_dir
        self.fuxi_dir = fuxi_dir
        self.sat_files = sat_files

    def __len__(self):
        return len(self.sat_files) - (PAST_FRAMES + FUTURE_FRAMES) + 1

    def __getitem__(self, idx):
        # Load satellite imagery sequence
        sat_sequence_files = self.sat_files[idx : idx + PAST_FRAMES + FUTURE_FRAMES]
        sat_data = [np.load(os.path.join(self.sat_dir, f)) for f in sat_sequence_files]
        sat_sequence = np.stack(sat_data, axis=0)
        
        # Load corresponding FuXi forecast
        fuxi_forecast_file = self.sat_files[idx].replace('satellite', 'fuxi_forecast')
        fuxi_data = np.load(os.path.join(self.fuxi_dir, fuxi_forecast_file))
        
        # Normalize
        sat_sequence = (sat_sequence - np.mean(sat_sequence)) / (np.std(sat_sequence) + 1e-6)
        fuxi_data = (fuxi_data - np.mean(fuxi_data)) / (np.std(fuxi_data) + 1e-6)

        past_frames = torch.from_numpy(sat_sequence[:PAST_FRAMES]).unsqueeze(0) # Add channel dim
        future_frames = torch.from_numpy(sat_sequence[PAST_FRAMES:]).unsqueeze(0) # Add channel dim
        fuxi_frames = torch.from_numpy(fuxi_data) # Already has channel dim
        
        return past_frames, future_frames, fuxi_frames

# --- Main Training Function ---
def p_losses(denoise_model, past_frames, future_frames, fuxi_frames, t):
    noise = torch.randn_like(future_frames)
    noisy_future_frames = q_sample(x_start=future_frames, t=t, noise=noise)
    
    # Concatenate inputs for the model
    # Model input: [past_frames, noisy_future_frames, fuxi_frames]
    # We need to match the channel dimension.
    # Let past be ch 1, future ch 1, fuxi ch 6. Total input channels = 8
    # The Unet3D will need to be initialized with `channels=8`
    
    # Let's align time dimension and concatenate on channel dimension
    # Past (B, 1, 8, H, W), Noisy Future (B, 1, 4, H, W), Fuxi (B, 6, 12, H, W)
    # This requires careful handling of tensor shapes. Let's simplify for the example.
    # We will concatenate the conditioning information with the noisy data.
    
    # Model input shape: (B, C, T, H, W)
    # Let's combine past + fuxi as conditioning and concat with noisy future data
    # For simplicity, let's use fuxi data as the primary condition.
    # Input to model will be noisy future frames + fuxi frames concatenated on channel dim.
    # Input shape: (B, 1+6, T, H, W). T must match. Let's use FUTURE_FRAMES length.
    
    model_input = torch.cat([noisy_future_frames, fuxi_frames[:, :, :FUTURE_FRAMES, :, :]], dim=1)
    
    predicted_noise = denoise_model(model_input, t)
    
    loss = F.smooth_l1_loss(noise, predicted_noise)
    return loss

def setup(rank, world_size):
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '12355'
    dist.init_process_group("nccl", rank=rank, world_size=world_size)

def cleanup():
    dist.destroy_process_group()

def train(rank, world_size):
    setup(rank, world_size)
    device = torch.device("cuda", rank)

    # Model input channels = 1 (future frames) + 6 (fuxi condition)
    model = Unet3D(dim=64, channels=1 + 6, out_dim=1, dim_mults=(1, 2, 4, 8)).to(device)
    ddp_model = DDP(model, device_ids=[rank])
    
    optimizer = AdamW(ddp_model.parameters(), lr=LEARNING_RATE)
    
    all_sat_files = sorted(os.listdir(SATELLITE_DATA_DIR))
    dataset = SatcastDataset(SATELLITE_DATA_DIR, FUXI_FORECAST_DIR, all_sat_files)
    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=sampler)

    for epoch in range(EPOCHS):
        sampler.set_epoch(epoch)
        ddp_model.train()
        
        progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}", disable=(rank!=0))
        for past, future, fuxi in progress_bar:
            past, future, fuxi = past.to(device), future.to(device), fuxi.to(device)
            
            optimizer.zero_grad()
            
            t = torch.randint(0, TIMESTEPS, (future.shape[0],), device=device).long()
            loss = p_losses(ddp_model, past, future, fuxi, t)
            
            loss.backward()
            optimizer.step()
            
            if rank == 0:
                progress_bar.set_postfix(loss=loss.item())

        if rank == 0 and (epoch + 1) % 50 == 0:
            torch.save(ddp_model.module.state_dict(), f'satcast_phase1_epoch_{epoch+1}.pth')
            
    cleanup()

if __name__ == '__main__':
    world_size = torch.cuda.device_count()
    torch.multiprocessing.spawn(train, args=(world_size,), nprocs=world_size, join=True)